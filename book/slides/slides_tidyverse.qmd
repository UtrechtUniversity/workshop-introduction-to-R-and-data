---
title: "The data science workflow with Tidyverse"
subtitle: "Afternoon session: Tidyverse"
author: "Research Data Management Support"
execute: 
  eval: true
  echo: true
format: 
  revealjs:
    theme: default
    embed-resources: true
    smaller: true
  gfm:
    mermaid-format: png
---

<!-- NB this should come in a separate css file -->
```{css}
/* Make sure the code and code output is larger than the default */
/* Source: https://stackoverflow.com/questions/75907436/quarto-revealjs-increase-relative-font-size-of-code-chunks */
code.sourceCode {
  font-size: 1.4em;
  /* or try font-size: xx-large; */
}

/* Also increase the size of the cell output */
div.cell-output-stdout {
  font-size: 1.4em;
}
```
<!---->

# {background-color=#FFCD00}

![](https://www.tidyverse.org/images/hex-tidyverse.png "The Tidyverse logo"){fig-align="center"}

## What is the `tidyverse`?

> The tidyverse is an opinionated collection of R packages **designed for data science**. All packages **share an underlying design** philosophy, grammar, and data structures ([tidyverse.org](https://www.tidyverse.org/)).


![](https://elixir-luxembourg.org/assets/events_photos/2021_05_06_R_Tidyverse.png "Logos of common tidyverse packages"){fig-align="center"}

## Packages and functions

![](images/collection_package_function.png "Visualization of functions, packages and package collections like the Tidyverse")

## Working with packages and functions

1. Installing a package (once):

```r
#| label: install-package
install.packages("dplyr")
```

. . .

2. Loading a package (every time you want to use it):
```{r}
#| label: load-package
library(dplyr)
```

. . .

3. Now you can use functions from this package! (every time you want to use it)

```{r}
#| label: use-a-function
dplyr::rename(iris, petal_length = Petal.Length)
```

# Go to Exercise 0 in `datascience_exercises.Rmd`

## The Data Science workflow

![Source: [R 4 Data Science](https://r4ds.had.co.nz/introduction.html)](https://d33wubrfki0l68.cloudfront.net/571b056757d68e6df81a3e3853f54d3c76ad6efc/32d37/diagrams/data-science.png "The data science workflow."){fig-align="center"}

::: notes
We will move a data frame through the different steps in a data science workflow.
This means that often the results of one step will be the input for the next
:::

## `tidyverse` core packages 

![](images/tidyverse_packages_per_step.png)

::: notes
- `readr`: data import
- `tibble`: modern data frame object
- `stringr`: working with strings
- `forcats`: working with factors
- `tidyr`: data tidying
- `dplyr`: data manipulation
- `ggplot2`: data visualization
- `purrr`: functional programming
:::

## Afternoon workflow

::: {.incremental}
1. Read a file into R
2. Clean the data:
   - Filter on relevant rows
   - Select only relevant columns
3. Calculate a new column
4. Rename a column
5. Put the dataframe into a long (tidy) format
6. Summarize the dataframe
7. Visualize the dataframe
8. Write the summarized dataframe to a file
:::


# Side Trip:<br>We're Going To Antarctica...{background-color=#FFCD00}

## Data: `palmerpenguins`

- Observations about penguins from the Palmer Archipelago (Antarctica)
- Package created by Allison Horst for worldwide use
- species, island, culmen length and depth, flipper length, etc.

![](https://allisonhorst.github.io/palmerpenguins/reference/figures/lter_penguins.png){width="10%"}

# Importing Data {background-color=#FFCD00}

## Reading data into R

```{mermaid}
%%| echo: false
%%| fig-width: 25

flowchart LR
    %% Subgraph Styling
    subgraph Filesystem
        style Filesystem fill:#e0f7fa,stroke:#333,stroke-width:2px,color:#333,font-size:30px
        style A fill:#ffffff,stroke:#333,stroke-width:2px,color:#333,font-size:20px
        style C fill:#ffffff,stroke:#333,stroke-width:2px,color:#333,font-size:20px
        A[Data file <br>.tsv, .csv .xlsx]
        C[Exported File]
    end
    subgraph R-Environment
        style R-Environment fill:#e8f5e9,stroke:#333,stroke-width:2px,color:#333,font-size:30px
        style B fill:#ffffff,stroke:#333,stroke-width:2px,color:#333,font-size:20px
        style D fill:#ffffff,stroke:#333,stroke-width:2px,color:#333,font-size:20px
        B[df in <br>R Environment] --> |Transform, Tidy, <br>Model, Visualize| D[df in<br> R Environment]
    end

    %% Connections
    A -->|Read into R| B
    D -->|Export as File| C
```


## `readr`: Read Rectangular Text Data

To read text data, you need:

- **location** of the data (path)
- **delimiter** (value separator) of the data, e.g. `,`, `;` or `\t`
- **function** to use to read data into R

. . .

| Read *from* file | Write *to* file | Value separator |
| --- | --- | --- |
| `read_delim()`| `write_delim()` | catch-all: user needs to specify |
| `read_csv()`| `write_csv()` | comma separated |
| `read_csv2()`| `write_csv2()` | semicolon separated |
| `read_tsv()` | `write_tsv()` | tab separated |


## Reading non-text data file

For non-text data files, there are other R packages:

- `readxl`: Excel files
- `haven`: SPSS & STATA files
- `googlesheets4`: Google Sheets 
- `rvest`: HTML files

## Example: reading data

Read a file located in the same folder as your script:
```r
raw_tsv_data <- read_tsv("my_raw_data.tsv")
```

. . . 

Read a file located in a different folder:
```r
raw_csv_data <- read_csv("data/raw/my_raw_data.csv")
```

. . .

Or from the web:

```r
# Source: https://catalog.data.gov/dataset/electric-vehicle-population-data
electric_vehicles <- read_csv("https://data.wa.gov/api/views/f6w7-q2d2/rows.csv")
```

. . .

Bonus: use an in-built dataset from R

```r
data(iris)        # Observational data on iris flowers
data(mtcars)      # Motor Trend Car Road Tests

data()            # Check all the available in-built datasets!
```
# Go to Exercise 1, 2 and 3

```{r}
#| echo: false
library(tidyverse)
``` 

## Answers Exercise 1, 2 and 3

1. Reading the penguins dataset into R.

```{r}
#| echo: false
penguins <- read_tsv("../../course-materials/data/penguins.tsv")
```

```r
penguins <- read_tsv("data/penguins.tsv")
```

. . .

2. Reading penguins_isotopes.xlsx into R.

```{r}
#| echo: false
library(readxl)
penguins_isotopes <- read_excel("../../course-materials/data/penguins_isotopes.xlsx")
```

```r
penguins_isotopes <- read_excel(path = "data/penguins_isotopes.xlsx")
```

. . .

3. Writing `penguins_isotopes` to a csv file.

```r
write_csv(penguins_isotopes,
          file = "data/penguins_isotopes.csv")
```

# Selecting & filtering data {background-color=#FFCD00}

## `dplyr`: Data Manipulation

`dplyr` contains functions for many types of data manipulation, such as:

- `filter()`: select **rows** that meet one or several logical criteria
- `select()`: select (or drop) **columns**  
- `rename()`: change column name
- `mutate()`: transform column values or create new column
- `group_by()`: group data on one or more columns
- `summarize()`: reduces a group of data into a single row

## Filter

Selects **rows** in your dataframe.

Use:
```r
filter(your-dataframe, your-condition)
```

. . .

```{r}
#| output: false
#| echo: false
df <- data.frame(name = c("Ann", "Bob", "Chloe", "Dan"),
                 age = c(35,22,50,51),
                 country = c("UK","USA","USA","UK")
)
```

From the morning session: "From your dataframe `df`, return complete rows for everyone living in a country of your choice."

```{r}
#| eval: false

df[df$country=="UK", ]        # Base R
```

. . .

```{r}
filter(df, country == "UK")   # Tidyverse
```

## Select

Select or drop **columns** in your dataframe.

Basic use:
```r
select(your-dataframe, col1, col2)  # select col1 and col2
```

. . .


```r
select(your-dataframe, -col3)       # select all but col3
```
. . .

Use special [selecting functions](https://tidyselect.r-lib.org/reference/language.html)
```r
select(your-dataframe, contain("col"))    # select cols containing "col"
``` 

. . .

From the morning session: "Return the columns `name` and `age` together."

```{r}
#| eval: false
df[, c("name","age")]       # Base R
```

. . .

```{r}
select(df, name, age)       # Tidyverse
```


## Mutate

Transform column values, or create new column.

Basic use:
```r
mutate(your-dataframe, column_name = an_operation)
```

. . .


Add a new column:

```{r}
#| eval: false
df$adult <- c("adult", "minor",     # Base R
              "adult", "adult")
```

. . .

```{r}
df <- mutate(df,                    # Tidyverse
            adult = c("adult", "minor", "adult", "adult"))
```

## Rename

Renaming columns.

Basic use:
```r
rename(your-dataframe, new_column_name = old_column_name)
```

. . .


Rename a column:

```{r}
#| eval: false
df$Adult <- df$adult          # Base R
```

. . .

```{r}
df <- rename(df, Adult = adult) # Tidyverse
df
```

# Go to Exercise 4 - 7

## Answers exercise 4

4. Filter `penguins` to leave out the NAs.

```{r}
penguins_subset <- filter(penguins, !is.na(Sex))
```

. . .

Or
```{r}
penguins_subset <- filter(penguins, Sex == "MALE" | Sex == "FEMALE")
```

. . .

Or

```{r}
penguins_subset <- filter(penguins, Sex %in% c("MALE", "FEMALE"))
```

## Answers exercise 5

5. Select the columns Individual_ID, Species, Sex, Island, Culmen_Depth_mm and Culmen_Length_mm

```{r}
penguins_subset_2 <- select(penguins_subset, Individual_ID, Species,
                            Sex, Island, 
                            Culmen_Depth_mm, Culmen_Length_mm)
```

. . .

Or
```{r}
penguins_subset_2 <- select(penguins_subset, Individual_ID, Species,
                            Sex, Island, 
                            starts_with("Culmen"))
```

. . .

Or
```{r}
penguins_subset_2 <- select(penguins_subset, Individual_ID, Species,
                            Sex, Island, 
                            contains("Culmen"))
```

## Answers exercises 6 and 7

6. Use `mutate()` to create a new column `culmen_ratio`.

```{r}
penguins_subset_3 <- mutate(penguins_subset_2,
                            culmen_ratio = Culmen_Length_mm / Culmen_Depth_mm)
```

. . .

7. Rename the columns `Culmen_Length_mm` and `Culmen_Depth_mm`.

```{r}
penguins_subset_4 <- rename(penguins_subset_3,
                            length = Culmen_Length_mm, 
                            depth = Culmen_Depth_mm)
```

# Piping Operations {background-color=#FFCD00}

## `magrittr`: The Forward-Pipe Operator

A key tidyverse component that chains all data science steps together: 

`%>%`

. . .

Why?

- create an easily readable **pipeline of chained commands**
- no nested function calls
- no need to save intermediate R objects with `<-`
- easily add and/or delete steps in your pipeline without breaking the code

## Pipe operator: how it works

```{r}
#| eval: false
#| code-line-numbers: 1-2|4-5|7-8|10-11
# Name the object that you use as initial input
my_new_df <- df %>%
  
  # Perform a function using that object as input
  filter(adult == "adult") %>%
  
  # Add another operation
  select(name, age) %>%
  
  # And another, etc.
  mutate(adult = c("adult", "minor", "adult", "adult"))
  
```

. . .

Note:

- `df` is only mentioned once at the beginning
- final line of the operation does not get a `%>%`

# Go to exercise 8

## Answers exercise 8

Make a workflow that starts with the data `penguins` and subsequently applies your `filter`, `select`, `mutate` and `rename` operations.

```{r}
penguins_subset_5 <- penguins %>%
  
  # Filter out NAs
  filter(!is.na(Sex)) %>%
  
  # Select only relevant columns
  select(Individual_ID, Species, Sex, Island, starts_with("Culmen")) %>%
  
  # Add a new columns culmen_ratio
  mutate(culmen_ratio =  Culmen_Length_mm / Culmen_Depth_mm) %>%
  
  # Rename Culmen measurement columns
  rename(length = Culmen_Length_mm,
         depth = Culmen_Depth_mm)
  
```

# Tidy Data {background-color=#FFCD00}

## Tidy Data

> Tidy data sets are all alike; but every messy data set is messy in its own way ([Wickham/Grolemund, 2017](https://r4ds.had.co.nz/tidy-data.html)]

. . .

Tidy Data Principles: principles for structuring tabular data sets:

1. Each variable forms a column.
2. Each observation forms a row.
3. Each type of observational unit forms a table.

## Our df - but extended

```{r}
#| echo: false

df_ext <- df %>%
  mutate(mood_wk1 = c(4, 3, 4, 2),
         mood_wk2 = c(2, 3, 5, 4))

df_ext
```

. . .

Wide or long?

. . .

That's right: **wide**. Why is this not tidy?

. . .

- Values in column names
- Multiple observations per row

## Our extended df - Long format

```{r}
#| echo: false

df_long <- df_ext %>%
            pivot_longer(cols = starts_with("mood_"),
                        names_to = "week",
                        values_to = "mood") %>%
           mutate(week = as.numeric(gsub("mood_wk", "", week))) %>%
           arrange(name, week)

df_long
```

. . .

- 1 observation (week) per row
- multiple rows per individual

## Wide vs Long


::: columns
::: {.column width="53%"}
**Wide**

```{r}
#| echo: false
head(df_ext, 4)
```

- All observations on 1 individual in 1 row
- Not tidy

:::

::: {.column width="47%"}
:::  {.fragment}

**Long**

```{r}
#| echo: false
head(df_long, 4)
```

- No values as column headers
- Single observation (weight, mood) in a single row
- Often needed for data visualization
:::
:::
:::

## `tidyr`: Tidy Messy Data

Do It Yourself:

- `pivot_longer()`: lengthen data: more rows, fewer columns (long format, tidy)
- `pivot_wider()`: widen data: fewer rows, more columns (wide format)

. . .

BASIC use:
```r
pivot_longer(your-dataframe, cols = c(col_to_pivot1, col_to_pivot2, etc),
            names_to = "name_of_measurement",
            values_to = "values_of_measurement")
```

. . .

Check `?pivot_longer()` and Google! for examples and other function arguments.

. . .

In our example:

```r
pivot_longer(df_ext, 
             cols = starts_with("mood_"),
             names_to = "week",
             values_to = "mood")
```

# Go to Exercise 9

## Answer exercise 9

Transform the dataframe from wide to long format using the function `pivot_longer()`.

```{r}
penguins_long <- penguins_subset_5 %>%
  pivot_longer(cols = c(length, depth),
               names_to = "culmen_element",
               values_to = "measurement")
```

## `group_by` and `summarize()`

Some text here

## Combining data

Full join, left join, right join

Example

The function `full_join()` takes two datasets, and merges them, based on a column or multiple columns that contain shared values. These columns can be found automatically by the function, or they can be indicated with the argument `by`.

If you want to know more about this set of operations, read R for Data Science, [chapter 13.4.1](https://r4ds.had.co.nz/relational-data.html#understanding-joins).


# Data Visualization {background-color=#FFCD00}

## New

Use the flipbook to show how ggplot works.

## `ggplot2`: Elegant Data Visualisations

`ggplot2` is Hadley Wickham's [reimplementation](https://www.tandfonline.com/doi/abs/10.1198/jcgs.2009.07098) of the 2005 published *The Grammar of Graphics* by Leland Wilkinson. It provides a large amount of functions for generating high-quality graphs in a layer-based fashion and has even sparked a whole ecosystem of 'gg'-style visualization packages.

```{r, echo=F, out.width='90%', out.height='90%', fig.align='center'}
knitr::include_graphics("https://simonschoe.github.io/introduction-to-the-tidyverse/img/grammar-of-graphic-layers.png")
```

## `ggplot2`: Elegant Data Visualisations

{{< video https://vimeo.com/470862707 >}}

## `ggplot2`: Elegant Data Visualisations

Let's check out the `ggplot flipbook`[https://evamaerey.github.io/ggplot_flipbook/ggplot_flipbook_xaringan.html](https://evamaerey.github.io/ggplot_flipbook/ggplot_flipbook_xaringan.html)

